# brainload Development information

This document is intended for developers who work on `brainload`. Users should ignore this file and install a release via `pip` instead. See the [README file in the repo root](../README.md) for details.

While `brainload` works on several platforms, development happens under Linux and sometimes MacOS, and this document and the development scripts assume a POSIX environment.

## Essential tools

You will need Python and some standard development tools. Under Linux, this should be enough:

```console
sudo apt-get install python-pip build-essential git
```

## Development installation

It is recommended to use a virtual environment for hacking on `brainload`. First, clone the repo:

```console
mkdir ~/develop/          # replace this dir with whatever you like or use an existing directory where you store all your code or projects.
cd ~/develop
git clone https://github.com/dfsp-spirit/brainload
cd brainload/             # we will refer to this directory as the `repository root` or `repo root` throughout this document.
```

Now let's prepare the dev environment. In the repo root:

```console
pip install --user virtualenv      # unless you already have it
python -m virtualenv env/          # creates a virtual python environment in the new directory `env/` in the repo root, i.e., `~/develop/brainload/env/` in our example
```


Note: Once you have created the virtual environment, all you have to do is use it:

```console
cd ~/develop/brainload             # replace with your repo root
source env/bin/activate            # to activate the virtual environment

some_command...                    # run stuff
another_command...

deactivate                         # to leave it
```

Ensure that you are still in the repo root, then activate the virtual environment and install `brainload` in development mode:

```console
source env/bin/activate
pip install --editable .           # installs brainload from the current directory, and grabs its dependencies from PyPI
```

You can now use the `brainload` module by typing `import brainload` in your python application or an interactive python session. Changes you make to the module source are applied automatically.



## Tests

Tests and test data are not shipped in the releases, clone the source repo and follow the installation instructions for the development version if you want to run them. Once you have done that, continue from here.

### Running the tests locally

#### Obtaining the test data

Not all data is included with the repo, as the test data is quite large and some fake subjects are generated by copying others. The good news is that you can get all test data by running a single shell script from the repo root:

```console
cd ~/develop/brainload               # replace with your repo root
./develop/get_test_data_all.bash
```

The script downloads all required [neuroimaging test data from Github](https://github.com/dfsp-spirit/neuroimaging_testdata). If you have a properly configured local installation of FreeSurfer (with environment variable `FREESURFER_HOME` pointing to the installation directory), it will prefer that for some data.

#### Running the tests

The easiest it to use the integration into `setup.py`, as this will install all test dependencies for you automatically. In the virtual environment and the top-level brainload directory, just run:

```console
python setup.py test
```


### Continuous Integration

The tests are run automatically when you push to master and developers get results by email. Build status from travis-ci.org (Linux, branch master):

[![Build Status](https://travis-ci.org/dfsp-spirit/brainload.svg?branch=master)](https://travis-ci.org/dfsp-spirit/brainload)

Note that not all test data is available on Travis and as a result, some tests get skipped. We are working on this. When run locally with all test data, coverage must be greater than 95% for all files.


## Packaging

If you want to get the tools you need for all steps below right now and all at once:

```console
pip install --upgrade setuptools wheel twine sphinx sphinx_rtd_theme
conda install conda-build anaconda-client
```

### Creating the release package


#### Update version information

Set the new version information:

```console
export NEW_VERSION="0.0.2"
export NEW_RELEASE="v${NEW_VERSION}"
cd ~/develop/brainload/        # repo root
git checkout master
git pull

vim setup.py                   # update 'version' in here
vim doc/conf.py                # update 'version' and 'release' in here
vim MANIFEST.in                # update the new documentation to include: docs/${NEW_RELEASE}/ (hard-code the number, of course)

git add setup.py doc/conf.py
```

#### Build docs

First note the difference between the directories 'doc' (source for documentation and sphinx templates) and 'docs' (Github page made containing the generated documentation). Do not confuse them.

We use sphinx with the theme from `readthedocs.org` to generate the documentation. In the virtual environment:

```console
pip install sphinx sphinx_rtd_theme
```

Now build the documentation:

```console
cd doc/
make html
```

This will build the documentation in HTML format and place it in `doc/_build/html/`. Now copy it to the correct location to be included in the release:

```console
cd ..    # back to repo root
mkdir docs/${NEW_RELEASE)/
cp -r doc/_build/html/* docs/${NEW_RELEASE}/
```

The [Brainload API documentation](http://dfsp-spirit.github.io/brainload) is made available on the internet using Github Pages, and our page is served from the directory `docs/` (note the `s` at the end) in this repo. You have to update the following HTML files:

- `docs/index.html`
- `docs/versions.html`

Now it's time to add all those changes to git:

```console
git add docs/${NEW_RELEASE)
git add docs/index.html docs/versions.html
git commit -m "Update version to ${NEW_VERSION}, add generated documentation."
```


#### Build the packages for PyPI / pip

We use setuptools for building:

```console
pip install --upgrade setuptools wheel              # just make sure we have the latest versions
rm -rf dist/
python setup.py sdist bdist_wheel --universal
```

Carefully check the output of the command for warnings or errors: wrong information in `setup.py` or `MANIFEST.in` may become obvious. If something is wrong, fix it and commit again.

### Distributing the packages


We are more or less just following the [official Python packaging user guide](https://packaging.python.org/tutorials/packaging-projects/) here. First make sure you have the required tools:

```console
pip install --upgrade twine            # in the virtual env. Add `--user` if you prefer to do it outside.
```

#### PyPI testing

```console
twine upload --repository-url https://test.pypi.org/legacy/ dist/*     # will ask for your PyPI test credentials for brainload
```

Now try it in a fresh virtual environment (you may have to wait a sec for it to become available):

```console
deactivate                                  # leave current virtual env
python -m virtualenv env_for_v2             # create a fresh one
source env_for_v2/bin/activate              # activate it
pip install --index-url https://test.pypi.org/simple/ brainload     # install it.
#now try the example client.
deactivate
rm -rf env_for_v2
```

If something is wrong, fix it and commit again. If everything looks fine, tag the current version as the new release:

```console
git tag -a ${NEW_RELEASE} -m "Some annotation for this release."
git push origin --tags
```

It is finally time to upload it to the real PyPI:

#### PyPI

```console
twine upload dist/*                           # will ask for your PyPI credentials for brainload
```

#### Anaconda (build and distribution)

This is WIP, see https://conda.io/docs/user-guide/tutorials/build-pkgs.html for instructions.

IMPORTANT: This builds the anaconda package based on the PyPI package, so you have to upload to PyPI before starting this.

Some work has already been done, see the files in `development/anaconda_dist`.

Get the tools: install `conda` on your system and fire it up, then use it to get the build tools. We will assume you installed it into `~/software/anaconda2`.

The first step is to activate conda if it is not active. Type `conda --version` to check, it the command is not found:

```console
export CONDA_BIN=${HOME}/software/anaconda2/bin
export PATH=${PATH}:${CONDA_BIN}
conda --version
```

Let's create a new environment and install the required tools into it:

```console
cd develop/anaconda_dist
conda update conda
conda create --name blbuild python=2.7
conda activate blbuild
conda install conda-build anaconda-client
conda skeleton pypi brainload --version ${NEW_VERSION}
conda config --add channels conda-forge      # add channel so the next command will find dependencies, e.g., nibabel
conda-build brainload                        # may take a while... will output the full path to the file in the end. You will need this soon.
conda deactivate
```

Now, update the `meta.yaml` file with the build information, e.g., the files to include. This is the main step.

When that is done, build and upload the package:

```console
anaconda login                   # will ask for your credentials
anaconda upload full/path/to/package.tar.bz2
```
